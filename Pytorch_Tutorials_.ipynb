{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial\n",
    "\n",
    "基本的に，以下のPyTorch初心者向けの公式ドキュメントに記載のものをそのまま動かしたものです。\n",
    "\n",
    "説明を付記しました。\n",
    "\n",
    "Reference:\n",
    "\n",
    "PyTorch Tutorial\n",
    "\n",
    "http://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\n",
    "\n",
    "## PyTorchとは\n",
    "\n",
    "- 深層学習研究のプラットフォーム\n",
    "- numpyよりも優れた，GPU上での計算の仕組みを提供する\n",
    "\n",
    "## はじめに\n",
    "\n",
    "### Tensors\n",
    "\n",
    "PyTorchの基本は`torch.Tensor`に含まれる`Tensor`型。\n",
    "\n",
    "`Tensor`は`numpy.ndarray`に似ているが，`Tensor`はGPU上での計算において優れた型である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "初期化されていない（5, 3）行列を`Tensor`型で宣言すると："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-2.4642e-07  4.5637e-41 -2.4642e-07\n",
       " 4.5637e-41         nan  2.2493e-40\n",
       " 4.4721e+21  1.6647e-41  6.7262e-44\n",
       " 0.0000e+00  6.7262e-44  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "乱数で初期化した（5, 3）行列を`Tensor`型で宣言すると"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0411  0.8354  0.4958\n",
       " 0.8536  0.0238  0.7862\n",
       " 0.0440  0.2469  0.2528\n",
       " 0.6852  0.2259  0.2360\n",
       " 0.2849  0.8614  0.7844\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "サイズの確認は："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Operations：演算\n",
    "\n",
    "四則演算について，様々な表記がある。\n",
    "\n",
    "例えば,加算についてみていく。\n",
    "\n",
    "加算方法１："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4565  1.7649  0.5953\n",
       " 1.7001  0.1802  0.9959\n",
       " 1.0320  0.7855  0.3711\n",
       " 1.2973  0.9961  0.7011\n",
       " 0.8641  1.3341  1.1177\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "加算方法２："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.4565  1.7649  0.5953\n",
      " 1.7001  0.1802  0.9959\n",
      " 1.0320  0.7855  0.3711\n",
      " 1.2973  0.9961  0.7011\n",
      " 0.8641  1.3341  1.1177\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "加算方法３："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4565  1.7649  0.5953\n",
       " 1.7001  0.1802  0.9959\n",
       " 1.0320  0.7855  0.3711\n",
       " 1.2973  0.9961  0.7011\n",
       " 0.8641  1.3341  1.1177\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.Tensor(5, 3)      # make empty (5, 3) Tensor\n",
    "torch.add(x, y, out = result)    # input x + y to Tensor\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "加算方法４："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4565  1.7649  0.5953\n",
       " 1.7001  0.1802  0.9959\n",
       " 1.0320  0.7855  0.3711\n",
       " 1.2973  0.9961  0.7011\n",
       " 0.8641  1.3341  1.1177\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x)     # \"add_(x)\" -> y = y + x \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "基本的に，演算の関数の後に `_` がついているものは代入の操作を表す。\n",
    "上記の例では，\n",
    "```Python\n",
    "y.add_(x)\n",
    "```\n",
    "は，`y = y+x`を行うことと同じ。\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy`と同じように，次のようにインデックスを指定できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8354\n",
       " 0.0238\n",
       " 0.2469\n",
       " 0.2259\n",
       " 0.8614\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### あとで読みたい\n",
    "`Tensor`の演算は他にも，インデックス，スライス，線形代数の演算などが100以上ある。詳細は[こちら](http://pytorch.org/docs/torch)。\n",
    "\n",
    "***\n",
    "\n",
    "## `Torch.Tensor`と`numpy`を行ったり来たり\n",
    "\n",
    "`Torch.Tensor`と`numpy`の要素は，同じメモリの場所に格納されており，相互の変換は簡単にできる。\n",
    "\n",
    "### `numpy`への変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "ここで，面白いことに…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "[ 2.  2.  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### `torch.Tensor`に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  2.  2.  2.]\n",
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU上の`Tensor`は，全て`numpy`に変換できるらしい（GPU上のTensorは変換できないということだろうか）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `autograd`と`Variable`\n",
    "\n",
    "Autogradは”automatic differentiation”のことで，そのパッケージである`autograd`はPyTorchの中核を担っている。これから，`autograd`に少し触れてみて，それをもとにニューラルネットワークを学習させてみよう。\n",
    "\n",
    "`autograd`パッケージは，Tensorの全ての演算に対して自動微分を行うためのもの。これは，PyTorchの特徴である\"define-by-run\"を実現している。つまり，順伝播のコードを書くだけで逆伝播が定義できる。\n",
    "\n",
    "### `Variable`\n",
    "\n",
    "- `autograd.Variable`が，`autograd`の中心的なパッケージである。`Variable`は`Tensor`のラッパーであり，`Tensor`のほぼ全ての演算が含まれている。\n",
    "- ネットワークを定義してしまえば，`.backward()`を呼び出すだけで勾配計算を自動的に行うことができる。\n",
    "\n",
    "Tensorの生データには`.data`でアクセスできる。そして，`Variable`に関する勾配は`.grad`に蓄積されている。`Variable`の概念図を以下に示す。\n",
    "\n",
    "![概念図](http://pytorch.org/tutorials/_images/Variable.png)\n",
    "\n",
    "### `Function`\n",
    "\n",
    "autogradに関して，もうひとつ重要なクラスがあります。それは`Function`と呼ばれるパッケージです。\n",
    "`Variable`と`Function`は内部でつながっていて，この２つによってニューラルネットワークのグラフが構築されます。そしてこのグラフに，ニューラルネットの計算の全ての履歴が残ります。\n",
    "\n",
    "生成されたvariableのそれぞれに`.grad_fn`という属性があり，この属性によってどの`Function`によってvariableが生成されたのかを参照できる。ただし，ユーザによって作られたvariableの場合`grad_fn`は`None`となる。\n",
    "\n",
    "variableの導関数を計算したいのであれば，variableがもっている`.backward()`を呼び出すと良い。もしvariableが単一の要素だけのとき，`backward()`には特に引数を指定する必要はないが，複数の要素をもつときは引数`grad_output`を指定してやる必要がある（←どういうこと？）。\n",
    "\n",
    "と言っても分かりづらいので，具体例を交えながら見ていきましょう。\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "variableを作ってみます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.ones(2, 2), requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "次に，variableの加算をしてみましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3  3\n",
       " 3  3\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "さっき言ったように，何らかの演算の後に生成されたvariableには属性`grad_fn`が付与されます。`y`の`grad_fn`を参照してみると："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x7f3882bda748>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "`y`にもっと色んな演算をしていきます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 27  27\n",
      " 27  27\n",
      "[torch.FloatTensor of size 2x2]\n",
      " Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 勾配計算\n",
    "\n",
    "いよいよ逆伝播の計算です。\n",
    "次に行う`out.backward()`は，`out.backward(torch.tensor([1.0]))`と等価です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "勾配を出力してみましょう。勾配とはすなわち $\\frac{d({\\rm out})}{dx}$　のことです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4.5000  4.5000\n",
       " 4.5000  4.5000\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.5`の要素をもつ行列（テンソル）が得られました。\n",
    "\n",
    "これはどういうことなのでしょうか？\n",
    "\n",
    "`out` Variable を\"$o$\"と呼ぶことにします。$o$は，次式で得られます。\n",
    "\n",
    "$o = \\frac{1}{4}\\sum_i z_i$\n",
    "\n",
    "ここで，$z_i = 3(x_i + 2)^2$ですから，\n",
    "\n",
    "$\\frac{\\partial o}{\\partial x_i}=\\frac{3}{2}(x_i + 2)$\n",
    "\n",
    "$x_i$の各要素は$1$なので，\n",
    "\n",
    "\n",
    "$\\frac{\\partial o}{\\partial x_i}|_{x_i = 1} = 4.5$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d (1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d (6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120)\n",
      "  (fc2): Linear(in_features=120, out_features=84)\n",
      "  (fc3): Linear(in_features=84, out_features=10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weighty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.0744  0.0788 -0.0589 -0.0867  0.0384  0.0192  0.1100  0.0702 -0.0357 -0.1127\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1, 1, 32, 32))\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad() \n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
